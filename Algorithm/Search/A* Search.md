---
상위 개념: "[[Informed Search]]"
---
# A* Search
A* 탐색은 목표 상태에 가까운 노드만을 우선적으로 확장함으로써, 불필요한 탐색을 줄이고 보다 효율적으로 최적 경로를 찾는 알고리즘이다.. 즉, 정답과 거리가 멀다고 판단되는 노드의 확장을 피함으로써 전체 탐색 횟수를 최소화하고, 휴리스틱 함수를 활용해 목표 상태에 빠르게 도달한다.

## 평가함수 f(n)
A* 탐색에서 노드들이 얼마나 목표 상태에 가까운지는 평가함수 f(n)을 통해 계산한다.

$$ f(n) = g(n) + h(n)$$
$g(n)$은 초기 상태로부터 현재 상태까지 오는데에 발생한 비용이다. $h(n)$은 현재 상태로부터 목표 상태가 될 때까지의 예측 비용이다. 평가함수는 두 값의 합으로 이루어진다.

시작 노드로부터 시작하여 어떤 노드를 확장할지는 각 노드의 평가함수에 의해 결정된다. 평가값이 가장 매력적인 노드는 확장되어 다음 상태를 낳는다.

## Admissible heuristic
A\* 탐색이 최적해(optimal solution)를 보장하기 위해서는 휴리스틱 함수 $h(n)$이 Admissible, 즉 낙관적(optimistic)이어야 한다. 이는 실제 비용 $h*(n)$보다 항상 작거나 같은 값을 반환해야 함을 의미한다.

1. $h(n) \le h*(n)$ — 실제 남은 비용보다 작게 추정해야 한다.
    
 이렇게 해야 탐색 알고리즘이 “가능한 더 좋은 경로가 있을 수 있다”고 판단하고, 목표 상태에 이르는 모든 잠재적 최단 경로를 고려할 수 있다. 만약 h(n)이 실제보다 크다면(과대평가), 어떤 경로가 실제로는 더 짧더라도 그 경로가 탐색되지 않을 수 있다. 즉, 최적해가 탐색되지 않고 누락될 위험이 생긴다.
    
1. $h(n) \ge 0$ — 휴리스틱은 음수가 될 수 없다.
    
 음수 비용을 허용하면 “이미 탐색한 노드보다 더 좋은 경로가 나중에 발견되는” 비정상적인 상황이 발생해, 알고리즘의 평가 함수 f(n) = g(n) + h(n)이 단조 증가(monotonic) 하지 않게 된다. 결과적으로, A\*의 우선순위 큐(open list)가 올바른 순서로 작동하지 않아 최적성 보장이 깨진다.

## h function derivation
원본 문제의 휴리스틱 함수를 완벽하게 유도하는 것은 어렵다. 따라서 Admissible Heuristics는 원본 문제를 단순화(relaxed)한 버전의 문제에 대한 솔루션 비용을 계산하는 것으로 유도한다.

> [!example] 8-puzzle problem
> 8-퍼즐 문제의 완벽한 솔루션 함수를 구하는 것은 어려움으로, 8 퍼즐 문제의 제약조건을 '타일은 어디로든 이동할 수 있다.', '타일은 인접한 곳과 위치를 바꿀 수 있다' 등으로 완화한다면 계산할 수 있는 휴리스틱 함수를 구할 수 있다. 당연히 단순화된 문제를 푸는 예측 비용은 원본 예측 비용보다 커서는 안된다.



## h(n)과 성능
A\* 탐색에서 휴리스틱 함수는 성능을 결정하는 핵심 요소이다.

만약 h(n) = 0 인 경우, 평가함수 f(n)은 그저 g(n)과 같으므로 다익스트라 알고리즘과 동일하게 작동한다. 이는 최적해는 찾겠지만, 탐색 범위가 매우 넓어 비효율적이다.

만약 h(n)이 h\*(n)과 완벽히 동일한 경우, 평가함수 f(n)은 완벽하게 비용을 예상하고, 불필요한 탐색은 전혀 발생하지 않는다.